{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d467745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this change to allow code DensePhrases to run from a jupyter notebook\n",
    "# L227 in DPhrases/options.py:\n",
    "#     opt, unknown = self.parser.parse_known_args()  # opt = self.parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c947053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE_DIR=../\n",
      "env: DATA_DIR=../densephrases-data\n",
      "env: SAVE_DIR=../outputs\n",
      "env: CACHE_DIR=../cache\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "\n",
    "%env BASE_DIR=../\n",
    "%env DATA_DIR=../densephrases-data\n",
    "%env SAVE_DIR=../outputs\n",
    "%env CACHE_DIR=../cache\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from integrate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4964e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS: Set inference parameters\n",
    "\n",
    "params = {\n",
    "    \"top_k\": 5,\n",
    "    \"use_large_index\": True,\n",
    "    \"strip_qmark\": False,\n",
    "    \"strip_qword1\": True,\n",
    "    \"strip_qword2\": False,\n",
    "    \"strip_qword_mode\": \"all\",  # first / all\n",
    "    \"prepend_hop_phrase\": False,\n",
    "    \"retrieval_unit\": \"phrase\",  # First hop only: phrase / sentence / paragraph\n",
    "    \"single_hop\": True,\n",
    "    \"mult_path_scores\": True\n",
    "}\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd82e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DensePhrases module...\n",
      "This could take up to 15 mins depending on the file reading speed of HDD/SSD\n",
      "Loading DensePhrases Completed!\n"
     ]
    }
   ],
   "source": [
    "# Load the DensePhrases module\n",
    "print(\"Loading DensePhrases module...\")\n",
    "model = load_densephrase_module(load_dir=load_dir, \n",
    "                                dump_dir=dump_dir, \n",
    "                                index_name=idx_name.replace('_small', ('' if params[\"use_large_index\"] \\\n",
    "                                                                       else '_small')), \n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a241af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /gypsum/scratch1/dagarwal/multihop_dense_retrieval/data/hotpot/hotpot_qas_val.json\n",
      "Read 5918 questions in 7405 total questions.\n"
     ]
    }
   ],
   "source": [
    "# Read questions and answers from data_path\n",
    "queries = read_queries(data_path)  #, bridge_only=False, filter_yes_no=True)\n",
    "questions = get_key(queries, 'question')\n",
    "answers = get_key(queries, 'answer')\n",
    "answers = [answer[0] for answer in answers]  # flattening\n",
    "\n",
    "# Setup function arguments based on the parameters\n",
    "method = 'pre' if params[\"prepend_hop_phrase\"] else 'post'\n",
    "top_k = params[\"top_k\"]\n",
    "ret_unit1 = params[\"retrieval_unit\"]\n",
    "strip_ques1 = params[\"strip_qmark\"]\n",
    "strip_prompt1 = params[\"strip_qword1\"]\n",
    "strip_ques2 = params[\"strip_qmark\"]\n",
    "strip_prompt2 = params[\"strip_qword2\"]\n",
    "strip_prompt_mode = params[\"strip_qword_mode\"]\n",
    "single_hop = params[\"single_hop\"]\n",
    "mult_path_scores = params[\"mult_path_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "698b552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batched multi-hop inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [16:10<00:00, 13.87s/it]\n"
     ]
    }
   ],
   "source": [
    "DEBUG=False\n",
    "if DEBUG:\n",
    "    ques = questions[:20]\n",
    "else:\n",
    "    ques = questions\n",
    "    \n",
    "# Run batched inference\n",
    "results = []\n",
    "print(\"Running batched multi-hop inference...\")\n",
    "for i in tqdm(range(0, len(ques), batch_size)):\n",
    "    batch_results = run_batch_inference(model, ques[i:i + batch_size], strip_ques1, strip_prompt1,\n",
    "                                        strip_ques2, strip_prompt2, ret_unit1, ret_unit2, ques_terms, method,\n",
    "                                        strip_prompt_mode, answers=answers[i:i + batch_size], write=False, \n",
    "                                        top_k=top_k, silent=True, single_hop=single_hop, mult_scores=mult_path_scores)\n",
    "    results += batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f8fe8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to disk\n",
    "def write_preds(results, params=None, prefix=None, single_hop=None):\n",
    "    run_id = __import__(\"calendar\").timegm(__import__(\"time\").gmtime())\n",
    "    \n",
    "    name = \"preds\" if prefix is None else prefix\n",
    "    if prefix is None and single_hop is not None:\n",
    "        name = 'predictions' if not single_hop else 'singlehop'\n",
    "    out_file = f'{name}_{run_id}.json'\n",
    "    \n",
    "    with open(out_file, 'w') as fp:\n",
    "        json.dump(results, fp, indent=4)\n",
    "    print(f\"Predictions saved at {out_file}\")\n",
    "    \n",
    "    if params is not None:\n",
    "        meta_out_file = out_file.replace('.json', '_meta.json')\n",
    "        with open(meta_out_file, 'w') as fp:\n",
    "            json.dump(params, fp, indent=4)\n",
    "        print(f\"Run metadata saved at {meta_out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ee89cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct oracle data\n",
    "\n",
    "import unicodedata\n",
    "def normalize(text):\n",
    "    \"\"\"Resolve different type of unicode encodings.\"\"\"\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "with open('../densephrases-data/hotpotqa/hotpot_dev_firsthop.json', 'r') as handle:\n",
    "    hotpot_dev = json.load(handle)\n",
    "\n",
    "oracle_sent_questions = []\n",
    "oracle_title_questions = []\n",
    "oracle_title_sent_questions = []\n",
    "oracle_all_sent_questions = []\n",
    "for h in hotpot_dev['data']:\n",
    "    q_sent_set = []\n",
    "    q_title_set = []\n",
    "    q_title_sent_set = []\n",
    "    q_all_sent_set = normalize(h['question'])\n",
    "    if h['type'] != 'bridge':\n",
    "        continue\n",
    "    for i in range(len(h['answers'])):\n",
    "        q_sent_set.append(normalize(h['question']) + \" \" + normalize(h['answers'][i]))\n",
    "        q_title_set.append(normalize(h['question']) + \" \" + normalize(h['titles'][i]))\n",
    "        q_title_sent_set.append(normalize(h['question']) + \" \" + normalize(h['titles'][i]) + \" \" + normalize(h['answers'][i]))\n",
    "        q_all_sent_set += \" \" + normalize(h['answers'][i])\n",
    "    oracle_sent_questions.append(list(set(q_sent_set)))\n",
    "    oracle_title_questions.append(list(set(q_title_set)))\n",
    "    oracle_title_sent_questions.append(list(set(q_title_sent_set)))\n",
    "    oracle_all_sent_questions.append(q_all_sent_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c21a9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at oracle_sent_preds_1648199883.json\n"
     ]
    }
   ],
   "source": [
    "# Oracle predictions - sentence-version\n",
    "sent_results = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    sent_results.append(run_oracle_inference(model, questions[i], oracle_sent_questions[i], answers[i]))\n",
    "\n",
    "write_preds(sent_results, prefix='oracle_sent_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6e0894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5918/5918 [14:43<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at oracle_title_preds_1648201162.json\n"
     ]
    }
   ],
   "source": [
    "# Oracle predictions - title-version\n",
    "title_results = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    title_results.append(run_oracle_inference(model, questions[i], oracle_title_questions[i], answers[i]))\n",
    "write_preds(title_results, prefix='oracle_title_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "481cf233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5918/5918 [15:59<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at oracle_title_sent_preds_1648202141.json\n"
     ]
    }
   ],
   "source": [
    "# Oracle predictions - title+sent-version\n",
    "title_sent_results = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    title_sent_results.append(run_oracle_inference(model, questions[i], oracle_title_sent_questions[i], answers[i]))\n",
    "write_preds(title_sent_results, prefix='oracle_title_sent_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "269ca105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5918/5918 [14:57<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at oracle_all_sent_preds_1648226462.json\n"
     ]
    }
   ],
   "source": [
    "# Oracle predictions - all_sents-version\n",
    "all_sent_results = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    all_sent_results.append(run_oracle_inference(model, questions[i], [oracle_all_sent_questions[i]], answers[i]))\n",
    "write_preds(all_sent_results, prefix='oracle_all_sent_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14043a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
